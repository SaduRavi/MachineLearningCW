kmeans_analysis(km2)
confusion_matrix(km2)
print("#####################")
print("####### k = 4 #######")
km3 <- kmeans(cleaned_df, 4, iter.max = 140 , algorithm="Lloyd", nstart=100)
kmeans_analysis(km3)
confusion_matrix(km3)
print("#####################")
print("################# K-means Clustering (Winner) ###################")
print("############################  k = 2 #############################")
print("The winning K-value of K-means Clustering is K = 2")
w_km <- kmeans(cleaned_df, 2, iter.max = 140 , algorithm="Lloyd", nstart=100)
print(paste("WSS : " , w_km$withinss ))
print(paste("BSS : " , w_km$betweenss ))
print(paste("BSS/TSS : " , w_km$betweenss/w_km$tot.withinss ))
print("#################################################################")
print("############################# PCA METHOD #########################")
#transformed = subset(df, select = -c(quality))
output <- prcomp(df, scale = TRUE)
summary(output)
oldpar = par(mfrow = c(1,1))
plot(output)
par(oldpar)
transformed = as.data.frame(-output$x[,10:11])
pca_km <- kmeans(transformed, 2, iter.max = 140 , algorithm="Lloyd", nstart=100)
pca_km
print(paste("WSS : " , pca_km$withinss ))
print(paste("BSS : " , pca_km$betweenss ))
print(paste("BSS/TSS : " , pca_km$betweenss/pca_km$tot.withinss ))
print("#################################################################")
#~~~~~~~~~~~~~~~~~~~~~~~~~~
# Name: Sadurshan Ravindran
# UoW ID: w1833588
# IIT ID: 20200596
#~~~~~~~~~~~~~~~~~~~~~~~~~~
# install.packages("readxl")  //installing package to read excel file
# install.packages("NbClust")
# install.packages('caret')
# install.packages('ConfusionTableR')
rm(list = ls())
library(readxl)
library(tidyverse)
library(NbClust)
library(factoextra)
df <- read_excel("Whitewine_v2.xlsx")  #storing the excel file
#View(df)                              #viewing the data set
df = mutate(df, quality = as_factor(df$quality))  # counting total quality for similar quality
summary(df)                                       # the summary of the data set includes min,max,mean
print_boxplot <- function() {   # Function to print box plot diagrams to visualize the data set
oldpar = par(mfrow = c(2,6))
for ( i in 1:11 ) {
boxplot(cleaned_df[[i]])
mtext(names(cleaned_df)[i], cex = 0.8, side = 1, line = 2)
}
par(oldpar)
}
############ OUTLIER DETECTION ##############
cleaned_df = df  # creating a clone of the data set
print_boxplot()  # print box plot diagrams to visualize before the outlier removal process
outliers = c()
for ( i in 1:11 ) {
statistics = boxplot.stats(cleaned_df[[i]])$stats
bottom_rows_outlier = which(cleaned_df[[i]] < statistics[1])
top_rows_outlier = which(cleaned_df[[i]] > statistics[5])
outliers = c(outliers , top_rows_outlier[ !top_rows_outlier %in% outliers ] )
outliers = c(outliers , bottom_rows_outlier[ !bottom_rows_outlier %in% outliers ] )
}
cleaned_df = cleaned_df[-outliers, ] # removing the outliers from the data set
new_df = cleaned_df
print_boxplot() # print box plot diagrams to visualize after the outlier removal process
#############################################
################# SCALING ###################
cleaned_df = subset(cleaned_df, select = -c(quality))
cleaned_df = scale(cleaned_df)
#View(cleaned_df)
summary(cleaned_df)
#############################################
################# DETERMINING THE OPTIMAL CLUSTER CENTERS ###################
#cluster_euclidean = NbClust(cleaned_df, distance = "euclidean", min.nc = 2, max.nc = 15, method = "kmeans",index = "all", alphaBeale = 0.1)
#fviz_nbclust(cleaned_df, kmeans, method = "wss") + geom_vline(xintercept = 2, linetype = 2) + labs(subtitle = "Elbow method")
#fviz_nbclust(cleaned_df, kmeans, method = "silhouette") + labs(subtitle = "Silhouette method")
#fviz_nbclust(cleaned_df, kmeans, nstart = 50,  method = "gap_stat", nboot = 50)+labs(subtitle = "Gap statistic method")
#############################################################################
indices_calculation <- function(cm, dp = 2) {
counts <- sum(cm)
column_sums <- colSums(cm)
row_sums <- rowSums(cm)
true_positive <- diag(cm)
false_positive <- row_sums - true_positive
false_negative <- column_sums - true_positive
precision <- true_positive / (true_positive + false_positive)
recall <- true_positive / (true_positive + false_negative)
accuracy <- sum(true_positive) / counts
print("Accuracy")
print(accuracy)
print("Precision")
print(precision)
print("Recall")
print(recall)
}
kmeans_analysis <- function(km) {
print(km)
print("************************************************************************* Cluster Centers *****************************************************************")
print(km$centers)
print("***********************************************************************************************************************************************************")
print("*")
print(paste("Between Cluster Sum of Squares" , km$betweenss))
print("*")
print("*")
print(paste("Total Sum of Squares" , km$totss))
print("*")
print("*")
print(paste("Ratio of BSS over TSS" ,km$betweenss/km$totss))
print("*")
print("*")
print(paste("Percentage",ceiling((km$betweenss/km$totss)*100)))
print("*")
}
confusion_matrix <- function(km) {
print("##############################################")
print("Confusion Matrix")
cm = as.matrix(table(Actual = new_df$quality, Predicted = km$cluster))
print(cm)
indices_calculation(cm)
print("Cluster Plot")
fviz_cluster(km, data = cleaned_df)
}
print("################# K-means Clustering ###################")
print("####### k = 2 #######")
km1 <- kmeans(cleaned_df, 2, iter.max = 140 , algorithm="Lloyd", nstart=100)
kmeans_analysis(km1)
confusion_matrix(km1)
print("#####################")
print("####### k = 3 #######")
km2 <- kmeans(cleaned_df, 3, iter.max = 140 , algorithm="Lloyd", nstart=100)
kmeans_analysis(km2)
confusion_matrix(km2)
print("#####################")
print("####### k = 4 #######")
km3 <- kmeans(cleaned_df, 4, iter.max = 140 , algorithm="Lloyd", nstart=100)
kmeans_analysis(km3)
confusion_matrix(km3)
print("#####################")
print("################# K-means Clustering (Winner) ###################")
print("############################  k = 2 #############################")
print("The winning K-value of K-means Clustering is K = 2")
w_km <- kmeans(cleaned_df, 2, iter.max = 140 , algorithm="Lloyd", nstart=100)
print(paste("WSS : " , w_km$withinss ))
print(paste("BSS : " , w_km$betweenss ))
print(paste("BSS/TSS : " , w_km$betweenss/w_km$tot.withinss ))
print("#################################################################")
print("############################# PCA METHOD #########################")
#transformed = subset(df, select = -c(quality))
output <- prcomp(df, scale = TRUE)
summary(output)
oldpar = par(mfrow = c(1,1))
plot(output)
par(oldpar)
transformed = as.data.frame(-output$x[,10:11])
pca_km <- kmeans(transformed, 2, iter.max = 140 , algorithm="Lloyd", nstart=100)
pca_km
print(paste("WSS : " , pca_km$withinss ))
print(paste("BSS : " , pca_km$betweenss ))
print(paste("BSS/TSS : " , pca_km$betweenss/pca_km$tot.withinss ))
print("#################################################################")
#~~~~~~~~~~~~~~~~~~~~~~~~~~
# Name: Sadurshan Ravindran
# UoW ID: w1833588
# IIT ID: 20200596
#~~~~~~~~~~~~~~~~~~~~~~~~~~
# install.packages("readxl")  //installing package to read excel file
# install.packages("NbClust")
# install.packages('caret')
# install.packages('ConfusionTableR')
rm(list = ls())
library(readxl)
library(tidyverse)
library(NbClust)
library(factoextra)
df <- read_excel("Whitewine_v2.xlsx")  #storing the excel file
#View(df)                              #viewing the data set
df = mutate(df, quality = as_factor(df$quality))  # counting total quality for similar quality
summary(df)                                       # the summary of the data set includes min,max,mean
print_boxplot <- function() {   # Function to print box plot diagrams to visualize the data set
oldpar = par(mfrow = c(2,6))
for ( i in 1:11 ) {
boxplot(cleaned_df[[i]])
mtext(names(cleaned_df)[i], cex = 0.8, side = 1, line = 2)
}
par(oldpar)
}
############ OUTLIER DETECTION ##############
cleaned_df = df  # creating a clone of the data set
print_boxplot()  # print box plot diagrams to visualize before the outlier removal process
outliers = c()
for ( i in 1:11 ) {
statistics = boxplot.stats(cleaned_df[[i]])$stats
bottom_rows_outlier = which(cleaned_df[[i]] < statistics[1])
top_rows_outlier = which(cleaned_df[[i]] > statistics[5])
outliers = c(outliers , top_rows_outlier[ !top_rows_outlier %in% outliers ] )
outliers = c(outliers , bottom_rows_outlier[ !bottom_rows_outlier %in% outliers ] )
}
cleaned_df = cleaned_df[-outliers, ] # removing the outliers from the data set
new_df = cleaned_df
print_boxplot() # print box plot diagrams to visualize after the outlier removal process
#############################################
################# SCALING ###################
cleaned_df = subset(cleaned_df, select = -c(quality))
cleaned_df = scale(cleaned_df)
#View(cleaned_df)
summary(cleaned_df)
#############################################
################# DETERMINING THE OPTIMAL CLUSTER CENTERS ###################
#cluster_euclidean = NbClust(cleaned_df, distance = "euclidean", min.nc = 2, max.nc = 15, method = "kmeans",index = "all", alphaBeale = 0.1)
#fviz_nbclust(cleaned_df, kmeans, method = "wss") + geom_vline(xintercept = 2, linetype = 2) + labs(subtitle = "Elbow method")
#fviz_nbclust(cleaned_df, kmeans, method = "silhouette") + labs(subtitle = "Silhouette method")
#fviz_nbclust(cleaned_df, kmeans, nstart = 50,  method = "gap_stat", nboot = 50)+labs(subtitle = "Gap statistic method")
#############################################################################
indices_calculation <- function(cm, dp = 2) {
counts <- sum(cm)
column_sums <- colSums(cm)
row_sums <- rowSums(cm)
true_positive <- diag(cm)
false_positive <- row_sums - true_positive
false_negative <- column_sums - true_positive
precision <- true_positive / (true_positive + false_positive)
recall <- true_positive / (true_positive + false_negative)
accuracy <- sum(true_positive) / counts
print("Accuracy")
print(accuracy)
print("Precision")
print(precision)
print("Recall")
print(recall)
}
kmeans_analysis <- function(km) {
print(km)
print("************************************************************************* Cluster Centers *****************************************************************")
print(km$centers)
print("***********************************************************************************************************************************************************")
print("*")
print(paste("Between Cluster Sum of Squares" , km$betweenss))
print("*")
print("*")
print(paste("Total Sum of Squares" , km$totss))
print("*")
print("*")
print(paste("Ratio of BSS over TSS" ,km$betweenss/km$totss))
print("*")
print("*")
print(paste("Percentage",ceiling((km$betweenss/km$totss)*100)))
print("*")
}
confusion_matrix <- function(km) {
print("##############################################")
print("Confusion Matrix")
cm = as.matrix(table(Actual = new_df$quality, Predicted = km$cluster))
print(cm)
indices_calculation(cm)
print("Cluster Plot")
fviz_cluster(km, data = cleaned_df)
}
print("################# K-means Clustering ###################")
print("####### k = 2 #######")
km1 <- kmeans(cleaned_df, 2, iter.max = 140 , algorithm="Lloyd", nstart=100)
kmeans_analysis(km1)
confusion_matrix(km1)
print("#####################")
print("####### k = 3 #######")
km2 <- kmeans(cleaned_df, 3, iter.max = 140 , algorithm="Lloyd", nstart=100)
kmeans_analysis(km2)
confusion_matrix(km2)
print("#####################")
print("####### k = 4 #######")
km3 <- kmeans(cleaned_df, 4, iter.max = 140 , algorithm="Lloyd", nstart=100)
kmeans_analysis(km3)
confusion_matrix(km3)
print("#####################")
print("################# K-means Clustering (Winner) ###################")
print("############################  k = 2 #############################")
print("The winning K-value of K-means Clustering is K = 2")
w_km <- kmeans(cleaned_df, 2, iter.max = 140 , algorithm="Lloyd", nstart=100)
print(paste("WSS : " , w_km$withinss ))
print(paste("BSS : " , w_km$betweenss ))
print(paste("BSS/TSS : " , w_km$betweenss/w_km$tot.withinss ))
print("#################################################################")
print("############################# PCA METHOD #########################")
transformed = subset(df, select = -c(quality))
output <- prcomp(df, scale = TRUE)
summary(output)
oldpar = par(mfrow = c(1,1))
plot(output)
par(oldpar)
transformed = as.data.frame(-output$x[,10:11])
pca_km <- kmeans(transformed, 2, iter.max = 140 , algorithm="Lloyd", nstart=100)
pca_km
print(paste("WSS : " , pca_km$withinss ))
print(paste("BSS : " , pca_km$betweenss ))
print(paste("BSS/TSS : " , pca_km$betweenss/pca_km$tot.withinss ))
print("#################################################################")
plot(output)
#~~~~~~~~~~~~~~~~~~~~~~~~~~
# Name: Sadurshan Ravindran
# UoW ID: w1833588
# IIT ID: 20200596
#~~~~~~~~~~~~~~~~~~~~~~~~~~
# install.packages("readxl")  //installing package to read excel file
# install.packages("NbClust")
# install.packages('caret')
# install.packages('ConfusionTableR')
rm(list = ls())
library(readxl)
library(tidyverse)
library(NbClust)
library(factoextra)
df <- read_excel("Whitewine_v2.xlsx")  #storing the excel file
#View(df)                              #viewing the data set
df = mutate(df, quality = as_factor(df$quality))  # counting total quality for similar quality
summary(df)                                       # the summary of the data set includes min,max,mean
print_boxplot <- function() {   # Function to print box plot diagrams to visualize the data set
oldpar = par(mfrow = c(2,6))
for ( i in 1:11 ) {
boxplot(cleaned_df[[i]])
mtext(names(cleaned_df)[i], cex = 0.8, side = 1, line = 2)
}
par(oldpar)
}
############ OUTLIER DETECTION ##############
cleaned_df = df  # creating a clone of the data set
print_boxplot()  # print box plot diagrams to visualize before the outlier removal process
outliers = c()
for ( i in 1:11 ) {
statistics = boxplot.stats(cleaned_df[[i]])$stats
bottom_rows_outlier = which(cleaned_df[[i]] < statistics[1])
top_rows_outlier = which(cleaned_df[[i]] > statistics[5])
outliers = c(outliers , top_rows_outlier[ !top_rows_outlier %in% outliers ] )
outliers = c(outliers , bottom_rows_outlier[ !bottom_rows_outlier %in% outliers ] )
}
cleaned_df = cleaned_df[-outliers, ] # removing the outliers from the data set
new_df = cleaned_df
print_boxplot() # print box plot diagrams to visualize after the outlier removal process
#############################################
################# SCALING ###################
cleaned_df = subset(cleaned_df, select = -c(quality))
cleaned_df = scale(cleaned_df)
#View(cleaned_df)
summary(cleaned_df)
#############################################
################# DETERMINING THE OPTIMAL CLUSTER CENTERS ###################
#cluster_euclidean = NbClust(cleaned_df, distance = "euclidean", min.nc = 2, max.nc = 15, method = "kmeans",index = "all", alphaBeale = 0.1)
#fviz_nbclust(cleaned_df, kmeans, method = "wss") + geom_vline(xintercept = 2, linetype = 2) + labs(subtitle = "Elbow method")
#fviz_nbclust(cleaned_df, kmeans, method = "silhouette") + labs(subtitle = "Silhouette method")
#fviz_nbclust(cleaned_df, kmeans, nstart = 50,  method = "gap_stat", nboot = 50)+labs(subtitle = "Gap statistic method")
#############################################################################
indices_calculation <- function(cm, dp = 2) {
counts <- sum(cm)
column_sums <- colSums(cm)
row_sums <- rowSums(cm)
true_positive <- diag(cm)
false_positive <- row_sums - true_positive
false_negative <- column_sums - true_positive
precision <- true_positive / (true_positive + false_positive)
recall <- true_positive / (true_positive + false_negative)
accuracy <- sum(true_positive) / counts
print("Accuracy")
print(accuracy)
print("Precision")
print(precision)
print("Recall")
print(recall)
}
kmeans_analysis <- function(km) {
print(km)
print("************************************************************************* Cluster Centers *****************************************************************")
print(km$centers)
print("***********************************************************************************************************************************************************")
print("*")
print(paste("Between Cluster Sum of Squares" , km$betweenss))
print("*")
print("*")
print(paste("Total Sum of Squares" , km$totss))
print("*")
print("*")
print(paste("Ratio of BSS over TSS" ,km$betweenss/km$totss))
print("*")
print("*")
print(paste("Percentage",ceiling((km$betweenss/km$totss)*100)))
print("*")
}
confusion_matrix <- function(km) {
print("##############################################")
print("Confusion Matrix")
cm = as.matrix(table(Actual = new_df$quality, Predicted = km$cluster))
print(cm)
indices_calculation(cm)
print("Cluster Plot")
fviz_cluster(km, data = cleaned_df)
}
print("################# K-means Clustering ###################")
print("####### k = 2 #######")
km1 <- kmeans(cleaned_df, 2, iter.max = 140 , algorithm="Lloyd", nstart=100)
kmeans_analysis(km1)
confusion_matrix(km1)
print("#####################")
print("####### k = 3 #######")
km2 <- kmeans(cleaned_df, 3, iter.max = 140 , algorithm="Lloyd", nstart=100)
kmeans_analysis(km2)
confusion_matrix(km2)
print("#####################")
print("####### k = 4 #######")
km3 <- kmeans(cleaned_df, 4, iter.max = 140 , algorithm="Lloyd", nstart=100)
kmeans_analysis(km3)
confusion_matrix(km3)
print("#####################")
print("################# K-means Clustering (Winner) ###################")
print("############################  k = 2 #############################")
print("The winning K-value of K-means Clustering is K = 2")
w_km <- kmeans(cleaned_df, 2, iter.max = 140 , algorithm="Lloyd", nstart=100)
print(paste("WSS : " , w_km$withinss ))
print(paste("BSS : " , w_km$betweenss ))
print(paste("BSS/TSS : " , w_km$betweenss/w_km$tot.withinss ))
print("#################################################################")
print("############################# PCA METHOD #########################")
transformed = subset(df, select = -c(quality))
output <- prcomp(transformed, scale = TRUE)
summary(output)
oldpar = par(mfrow = c(1,1))
plot(output)
par(oldpar)
transformed = as.data.frame(-output$x[,10:11])
pca_km <- kmeans(transformed, 2, iter.max = 140 , algorithm="Lloyd", nstart=100)
pca_km
print(paste("WSS : " , pca_km$withinss ))
print(paste("BSS : " , pca_km$betweenss ))
print(paste("BSS/TSS : " , pca_km$betweenss/pca_km$tot.withinss ))
print("#################################################################")
print("############################# PCA METHOD #########################")
transformed = subset(df, select = -c(quality))
output <- prcomp(transformed, scale = TRUE)
summary(output)
oldpar = par(mfrow = c(1,1))
plot(output)
par(oldpar)
transformed = as.data.frame(-output$x[,9:11])
pca_km <- kmeans(transformed, 2, iter.max = 140 , algorithm="Lloyd", nstart=100)
pca_km
print(paste("WSS : " , pca_km$withinss ))
print(paste("BSS : " , pca_km$betweenss ))
print(paste("BSS/TSS : " , pca_km$betweenss/pca_km$tot.withinss ))
print("#################################################################")
wss <- 0
# For 1 to 20 cluster centers
for (i in 1:10) {
km.out <- kmeans(scaleData, centers = i)
# Save total within sum of squares to wss variable
wss[i] <- km.out$tot.withinss
}
wss
# Plot total within sum of squares vs. number of clusters
plot(1:10, wss, type = "b",
xlab = "Number of Clusters",
ylab = "Within groups sum of squares")
View(cleaned_df)
wss <- 0
# For 1 to 20 cluster centers
for (i in 1:10) {
km.out <- kmeans(cleaned_df, centers = i)
# Save total within sum of squares to wss variable
wss[i] <- km.out$tot.withinss
}
wss
plot(1:10, wss, type = "b",
xlab = "Number of Clusters",
ylab = "Within groups sum of squares")
print_elbow_graph()
print_elbow_graph <- function() {
wss <- 0
for (i in 1:10) {
km.out <- kmeans(cleaned_df, centers = i)
wss[i] <- km.out$tot.withinss
}
plot(1:10, wss, type = "b", xlab = "Number of Clusters", ylab = "Within groups sum of squares")
}
print_elbow_graph()
print("############################# PCA METHOD #########################")
transformed = subset(df, select = -c(quality))
output <- prcomp(transformed, scale = TRUE)
summary(output)
oldpar = par(mfrow = c(1,1))
plot(output)
par(oldpar)
transformed = as.data.frame(-output$x[,9:11])
pca_km <- kmeans(transformed, 2, iter.max = 140 , algorithm="Lloyd", nstart=100)
pca_km
print(paste("WSS : " , pca_km$withinss ))
print(paste("BSS : " , pca_km$betweenss ))
print(paste("BSS/TSS : " , pca_km$betweenss/pca_km$tot.withinss ))
print("#################################################################")
print("############################# PCA METHOD #########################")
transformed = subset(df, select = -c(quality))
output <- prcomp(cleaned_df, scale = TRUE)
summary(output)
oldpar = par(mfrow = c(1,1))
plot(output)
par(oldpar)
transformed = as.data.frame(-output$x[,9:11])
pca_km <- kmeans(transformed, 2, iter.max = 140 , algorithm="Lloyd", nstart=100)
pca_km
print(paste("WSS : " , pca_km$withinss ))
print(paste("BSS : " , pca_km$betweenss ))
print(paste("BSS/TSS : " , pca_km$betweenss/pca_km$tot.withinss ))
print("#################################################################")

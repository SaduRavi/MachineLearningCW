#~~~~~~~~~~~~~~~~~~~~~~~~~~
# Name: Sadurshan Ravindran
# UoW ID: w1833588
# IIT ID: 20200596
#~~~~~~~~~~~~~~~~~~~~~~~~~~

# install.packages("readxl")  //installing package to read excel file 
# install.packages("NbClust")
# install.packages('caret')

rm(list = ls())  #reset the enivorment 
library(readxl)
library(tidyverse)
library(NbClust)
library(factoextra)

df <- read_excel("Whitewine_v2.xlsx")  #storing the excel file 
#View(df)                              #viewing the data set

df = mutate(df, quality = as_factor(df$quality))  # counting total quality for similar quality
summary(df)                                       # the summary of the data set includes min,max,mean

print_boxplot <- function() {   # Function to print box plot diagrams to visualize the data set as each class                                 
  oldpar = par(mfrow = c(2,6))  
  for ( i in 1:11 ) {
    boxplot(cleaned_df[[i]])
    mtext(names(cleaned_df)[i], cex = 0.8, side = 1, line = 2)
  }
  par(oldpar)
}

############ OUTLIER DETECTION ##############
cleaned_df = df  # creating a clone of the data set
print_boxplot()  # print box plot diagrams to visualize before the outlier removal process

outliers = c()  
for ( i in 1:11 ) {
  statistics = boxplot.stats(cleaned_df[[i]])$stats
  bottom_rows_outlier = which(cleaned_df[[i]] < statistics[1])   
  top_rows_outlier = which(cleaned_df[[i]] > statistics[5])
  outliers = c(outliers , top_rows_outlier[ !top_rows_outlier %in% outliers ] )
  outliers = c(outliers , bottom_rows_outlier[ !bottom_rows_outlier %in% outliers ] )
} 

cleaned_df = cleaned_df[-outliers, ] # removing the outliers from the data set 
new_df = cleaned_df
print_boxplot() # print box plot diagrams to visualize after the outlier removal process

#############################################

################# SCALING ###################
cleaned_df = subset(cleaned_df, select = -c(quality))
cleaned_df = scale(cleaned_df)
#View(cleaned_df)
summary(cleaned_df)
#############################################


print_elbow_graph <- function() {                                
  wss <- 0
  for (i in 1:10) {
    km.out <- kmeans(cleaned_df, centers = i)
    wss[i] <- km.out$tot.withinss
  }
  plot(1:10, wss, type = "b", xlab = "Clusters", ylab = "Within sum of squares")
}


################# DETERMINING THE OPTIMAL CLUSTER CENTERS ###################

#cluster_euclidean = NbClust(cleaned_df, distance = "euclidean", min.nc = 2, max.nc = 15, method = "kmeans",index = "all", alphaBeale = 0.1)

#fviz_nbclust(cleaned_df, kmeans, method = "wss") + geom_vline(xintercept = 2, linetype = 2) + labs(subtitle = "Elbow method")

#fviz_nbclust(cleaned_df, kmeans, method = "silhouette") + labs(subtitle = "Silhouette method")

#fviz_nbclust(cleaned_df, kmeans, nstart = 50,  method = "gap_stat", nboot = 50)+labs(subtitle = "Gap statistic method")

#print_elbow_graph()

#############################################################################





# method to calculate the necessary indices 
# input parameter is the confusion matrix
indices_calculation <- function(cm, dp = 2) {
  counts <- sum(cm)           # total sum
  column_sums <- colSums(cm)  # sum of the columns 
  row_sums <- rowSums(cm)     # sum of the rows 
  
  true_positive <- diag(cm)                       # true positive sum in the cm table
  false_positive <- row_sums - true_positive      # false positive sum in the cm table
  false_negative <- column_sums - true_positive   # false negative sum in the cm table
  
  precision <- true_positive / (true_positive + false_positive) # calculate precision 
  recall <- true_positive / (true_positive + false_negative)    # calculate recall
  accuracy <- sum(true_positive) / counts                       # calculate accuracy
  
  print("Accuracy")
  print(accuracy)
  
  print("Precision")
  print(precision)
  
  print("Recall")
  print(recall)
}

# method to calculate the kmeans values
# input parameter kmeans
kmeans_analysis <- function(km) {
  print(km)
  print("************************************************************************* Cluster Centers *****************************************************************")
  print(km$centers)
  print("***********************************************************************************************************************************************************")
  
  print("*")
  print(paste("Between Cluster Sum of Squares" , km$betweenss))
  print("*")
  
  print("*")
  print(paste("Total Sum of Squares" , km$totss))
  print("*")
  
  print("*")
  print(paste("Ratio of BSS over TSS" ,km$betweenss/km$totss))
  print("*")
  
  print("*")
  print(paste("Percentage",ceiling((km$betweenss/km$totss)*100)))
  print("*")
}

# method to build a confusion matrix 
# input parameter kmeans
confusion_matrix <- function(km) {
  print("##############################################")
  print("Confusion Matrix")
  cm = as.matrix(table(Actual = new_df$quality, Predicted = km$cluster))
  print(cm)
  indices_calculation(cm)
  
  print("Cluster Plot")
  fviz_cluster(km, data = cleaned_df)
}


print("################# K-means Clustering ###################")
print("####### k = 2 #######")
km1 <- kmeans(cleaned_df, 2, iter.max = 140 , algorithm="Lloyd", nstart=100)
kmeans_analysis(km1)
confusion_matrix(km1)
print("#####################")

print("####### k = 3 #######")
km2 <- kmeans(cleaned_df, 3, iter.max = 140 , algorithm="Lloyd", nstart=100)
kmeans_analysis(km2)
confusion_matrix(km2)
print("#####################")


print("####### k = 4 #######")
km3 <- kmeans(cleaned_df, 4, iter.max = 140 , algorithm="Lloyd", nstart=100)
kmeans_analysis(km3)
confusion_matrix(km3)
print("#####################")


print("################# K-means Clustering (Winner) ###################")
print("############################  k = 2 #############################") 
print("The winning K-value of K-means Clustering is K = 2")
w_km <- kmeans(cleaned_df, 2, iter.max = 140 , algorithm="Lloyd", nstart=100)
print(paste("WSS : " , w_km$withinss ))
print(paste("BSS : " , w_km$betweenss ))
print(paste("BSS/TSS : " , w_km$betweenss/w_km$tot.withinss ))
print("#################################################################")


print("############################# PCA METHOD #########################")
transformed = subset(df, select = -c(quality))
output <- prcomp(cleaned_df, scale = TRUE)
summary(output)
transformed = as.data.frame(-output$x[,9:11])
pca_km <- kmeans(transformed, 2, iter.max = 140 , algorithm="Lloyd", nstart=100)
pca_km
print(paste("WSS : " , pca_km$withinss ))
print(paste("BSS : " , pca_km$betweenss ))
print(paste("BSS/TSS : " , pca_km$betweenss/pca_km$tot.withinss ))
print("#################################################################")


